langchain4j:
  ollama:
    chat-model:
      enabled: true
      base-url: http://localhost:11434
      model-name: llama3


